"""
Create sets of terms (facets, search terms) to use in benchmark tests.
"""

import random

from utils import helpers
from utils.test_helpers import solr_test_profiles as stp


class TermChooser(object):
    """
    Ensure all terms get chosen when choosing randomly from a term set.

    This is a utility meant to be used with the gen function generators
    in this module. It allows you to provide a list of terms and
    weights and make repeated calls to `choose` to select from `terms`.
    All terms are used exactly once before random selection (using the
    provided `weights`) kicks in, and each individual call to `choose`
    ensures a group of unique values.

    Assuming you are populating a document set that is more populous
    than your terms list, this ensures all facet values are used at
    least once. (With weights featuring a long tail of very small
    weight values, purely random selection otherwise misses lots of
    terms.) This means, e.g., all of your terms will appear somewhere
    in your document set, and your facet cardinality will be exactly
    what you expect, which is important for testing Solr queries.

    The tradeoff is that your first len(terms) choices won't feature
    any repeated terms. For benchmarking purposes I don't think this
    makes a difference.
    """
    def __init__(self, terms, weights):
        self.terms = terms
        self.nterms = len(terms)
        self.weights = weights
        self.unused_terms = set(terms)

    def choose(self, num):
        vals = []
        num_unused = len(self.unused_terms)
        if self.unused_terms:
            if num_unused > num:
                vals = random.sample(list(self.unused_terms), k=num)
                self.unused_terms -= set(vals)
                return vals
            vals = list(self.unused_terms)
            self.unused_terms = set()
            num -= len(vals)
        choices = set()
        nchoices = 0
        while nchoices < num:
            num -= nchoices
            choices |= set(random.choices(self.terms, cum_weights=self.weights,
                                          k=num))
            nchoices = len(choices)
        vals.extend(list(choices))
        return vals


def make_vocabulary(num, gen=None):
    """
    Generate a vocabulary containing `num` unique terms.

    Pass an optional `gen` function to define how to generate each
    term. (See `utils.test_helpers.solr_test_profiles` for examples of
    existing gen functions and gen function generators. You can use any
    of these or provide your own; it just needs to be a function that
    takes a dictionary value and returns a value.) Default is the
    `solr_test_profiles.random_word` function, which creates a random
    alphabetic, alphanumeric, or numeric word.
    """
    gen = gen or stp.random_word
    words = set([])
    while len(words) < num:
        words.add(gen({}))
    return list(words)


def make_phrases(num, numwords, vocabulary, weights=None):
    """
    Generate `num` unique phrases from the given `vocabulary`.

    Phrases are of length `numwords`. Each word is chosen randomly from
    the vocabulary list. You can provide a list of `weights` for each
    word in the vocabulary if you need a certain word distribution.
    (Weights should be cumulative.)
    """
    phrases = set([])
    while len(phrases) < num:
        words = random.choices(vocabulary, cum_weights=weights, k=numwords)
        phrases.add(' '.join(words))
    return list(phrases)


def make_search_terms(num, gen=None, phrase_length_factors=None):
    """
    Generate `num` unique search terms/phrases to use in benchmarking.

    By default, per 100 terms, this generates:
        - 50 1-word terms
        - 25 2-word terms
        - 15 3-word terms
        - 8 4-word terms
        - 2 5-word terms

    The 1-word terms that are generated are used to make the multi-word
    phrases.

    You can change how many of each category are generated by passing a
    custom `phrase_length_factors` list. [0.5, 0.25, 0.15, 0.08, 0.02]
    is the default. If you want phrases with more or fewer words, just
    provide the appropriate number of elements. Factors don't have to
    add up to 1.0; just be aware that you'll get back a total of
    (sum(factors) * num) terms.

    Returns a dict, such as: {
        '1-word': [50 1-word terms],
        '2-word': [25 2-word terms],
        '3-word': [15 3-word terms],
        '4-word': [8 4-word terms],
        '5-word': [2 5-word terms],
        'all': [All 100 terms]
    }

    Term lists are sorted shortest to longest.
    """
    plfactors = phrase_length_factors or [0.5, 0.25, 0.15, 0.08, 0.02]
    terms = {'1-word': [], 'all': []}
    for i, plfactor in enumerate(plfactors):
        numwords = i + 1
        num_to_gen = int(round(num * plfactor))
        if numwords == 1:
            new_terms = make_vocabulary(num_to_gen, gen=gen)
        else:
            new_terms = make_phrases(num_to_gen, numwords, terms['1-word'])
        new_terms = sorted(new_terms)
        terms['{}-word'.format(numwords)] = new_terms
        terms['all'].extend(new_terms)
    return terms


def make_facet_terms(total_docs, facet_params, cardinality_floor=10):
    """
    Generate sets of facet terms based on a set of `facet_params`.

    The given `facet_params` should be a `parameters.FacetFieldParams`
    object. A set of unique terms is generated for each facet, where
    how many terms (cardinality) is controlled by `facet_params` and
    the total number of documents being generated (`total_docs`).

    You can set a default `cardinality_floor` to be used as the
    smallest number of terms that can be generated (if not overridden
    in `facet_params`). Default is 10.

    Returns a dict, where keys reflect facet fields (and are identical
    to keys in `facet_params`) and values are term lists for each
    corresponding facet field.
    """
    terms = {}
    for field, p in facet_params.items():
        fterms = set([])
        card = p.cardinality
        if card is None:
            floor = p.get('card_floor', cardinality_floor)
            multiplier = p.occ_factor * p.card_factor
            card = helpers.clamp(round(total_docs * multiplier), minnum=floor)
        terms[field] = make_vocabulary(card, p.gen)
    return terms


def make_terms_injector_gen(terms, weights, func, chance_of_0=0,
                            chance_of_injection=10, multi=True, mn=1, mx=5,
                            mu=1):
    """
    Generate a 'gen' function that injects terms into generated data.

    This creates a gen function (i.e. to use as part of a profile for
    generating mock Solr documents) for a field that contains search
    terms, where search terms are randomly injected to follow a given
    distribution over an entire document set. (Each term is used at
    least once, regardless.)

    First, it uses the provided `func` (function) to generate most of
    the data. (So, this should be a gen function corresponding to the
    kind of data you want in your field.) In general, it has a
    `chance_of_0` percent chance to generate no data at all, and if
    `multi` is True then it randomly generates between `mn` and `mx`
    values for a single field (where `mu` controls the average number).

    Then, it has a chance to embed a term from `terms` into the data.
    (Control this using percent `chance_of_injection`. Default is 10%.)
    When this happens, it uses the provided list of `weights` to select
    a term, where `weights` is a list of cumulative weights, one for
    each of `terms`.

    When embedding a term, it either overwrites one of the generated
    field values or gets injected somewhere in the middle. Which value
    to change and where to be injected are completely random. If
    injected, it creates spacing so that the terms still match when
    searched.
    """
    def _inject(val, newterm):
        pos = random.randint(1, len(val))
        return ' '.join([val[:pos], newterm, val[pos:]]).strip()

    chooser = TermChooser(terms, weights)

    def _gen(record):
        wrapped_func = func
        if multi:
            wrapped_func = stp.multi(func, mn, mx, mu=mu)
        if chance_of_0 > 0:
            wrapped_func = stp.chance(wrapped_func, chance=100-chance_of_0)
        val = wrapped_func(record)
        inject = random.choices([True, False], [chance_of_injection, 100])[0]
        if val and inject:
            newterm = chooser.choose(1)[0]
            overwrite = random.choice([True, False])
            if multi:
                to_change = random.randint(0, len(val)-1)
                if overwrite:
                    val[to_change] = newterm
                else:
                    val[to_change] = _inject(val[to_change], newterm)
            elif overwrite:
                val = newterm
            else:
                val = _inject(val, newterm)
        return val
    return _gen


def make_terms_gen(terms, weights, chance_of_0=0, multi=True, mn=1, mx=2, mu=1):
    """
    Generate a 'gen' function to create data using only specific terms.

    This creates a gen function (i.e. to use as part of a profile for
    generating mock Solr documents) for a facet field, where you want
    only the specified `terms` used. Terms are selected to follow a
    given distribution over an entire document set. (Each term is used
    at least once, provided a large enough document set.)

    If `multi` is True, your facet field is multivalued, and a unique
    set of `mn` to `mx` terms may be generated. (`mu` in this case is
    the average number of terms.)

    Use `chance_of_0` to control how often this field is left blank.
    (If a facet field has an occ_factor parameter, `chance_of_0` should
    be ((1.0 - occ_factor) * 100).)

    It uses your provided list of `weights` to select a term, where
    `weights` is a list of cumulative weights, one for each of `terms`.
    """
    chooser = TermChooser(terms, weights)
    num_weights = []
    if multi:
        dist_func = helpers.poiss_cdr
        num_weights = helpers.distribute(mx - mn + 1, dist_func, mu=mu)
    
    def _gen(record):
        if multi:
            k = random.choices(range(mn, mx + 1), cum_weights=num_weights)[0]
            return chooser.choose(k)
        return chooser.choose(1)[0]

    if chance_of_0 > 0:
        return stp.chance(_gen, chance=100-chance_of_0)
    return _gen

